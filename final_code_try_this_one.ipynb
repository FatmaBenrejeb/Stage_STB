{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6a6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "import time \n",
    "\n",
    "liens_publications =[]\n",
    "\n",
    "descriptions=[]\n",
    "\n",
    "reactions = []\n",
    "\n",
    "likes =[]\n",
    "loves =[]\n",
    "angryy =[]\n",
    "\n",
    "produits=[]\n",
    "\n",
    "\n",
    "def extract_publications_links():\n",
    "    publications = driver.find_elements_by_tag_name('article')\n",
    "    i=1\n",
    "    for pub in publications:\n",
    "        a = pub.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div[2]/div[1]/div/section/article['+str(i)+']/footer/div[2]/a[1]')\n",
    "        #print(a.get_attribute('href'))\n",
    "        liens_publications.append(a.get_attribute('href'))\n",
    "        i=i+1\n",
    "\n",
    "    \n",
    "    return(liens_publications)\n",
    "\n",
    "def extract_description(lien):\n",
    "    driver.get(lien)\n",
    "    description = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[1]/div/div/div[1]/div/p')\n",
    "    return(description.text)\n",
    "\n",
    "\n",
    "def produit_par_publication(pub):\n",
    "    res=\"\"\n",
    "    product_list=[\"carte\",\"بطاقة بنكية\",\"double salire\",\"credit\",\"Crédithabitat\",\"crédit\" ,\"9ardh\",\"9arth\",\"cartebancaire\",\"DigiCarte\",\"STBNet\"]\n",
    "    for p in product_list:\n",
    "        if(type(pub)==list):\n",
    "            break\n",
    "        if(pub.find(p)!=-1):\n",
    "            if(p==\"بطاقة بنكية\"): \n",
    "                res=\"Carte Banquaire\"\n",
    "            break\n",
    "        else:\n",
    "            res=\"Neutre\"\n",
    "    return(res)\n",
    "\n",
    "def nombre_reactions():\n",
    "    i=1\n",
    "    while(i<6):\n",
    "        react = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div[2]/div[1]/div/section/article['+str(i)+']/footer/div[2]/span[1]/a[1]').text\n",
    "        i=i+1\n",
    "        #print(react)\n",
    "        reactions.append(react)\n",
    "    return(reactions)\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('/Users/Dream/Desktop/Test/chromedriver')\n",
    "driver.get('https://mbasic.facebook.com')\n",
    "\n",
    "\n",
    "# Step 3) Search & Enter the Email or Phone field & Enter Password\n",
    "username = driver.find_element_by_id(\"m_login_email\")\n",
    "password = driver.find_element_by_name(\"pass\")\n",
    "submit   = driver.find_element_by_name(\"login\")\n",
    "username.send_keys(\"\")\n",
    "password.send_keys(\"\")\n",
    "# Step 4) Click Login\n",
    "submit.click()\n",
    "time.sleep(10)\n",
    "\n",
    "confirm = driver.find_element_by_xpath('/html/body/div/div/div/div/table/tbody/tr/td/div/form/div/input')\n",
    "confirm.click()\n",
    "time.sleep(10)\n",
    "\n",
    "search = driver.find_element_by_xpath('/html/body/div/div/div[1]/div/form/table/tbody/tr/td[2]/input')\n",
    "search.send_keys(\"SocieteTunisiennedeBanque\")\n",
    "search.send_keys(Keys.ENTER)\n",
    "time.sleep(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85640f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stb = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/div[1]/div[2]/div[1]/div[1]/div/div/section/div/div/div/div/article/div/header/table/tbody/tr/td[2]/header/h3/span/strong/a')\n",
    "stb.click()\n",
    "time.sleep(10)\n",
    "\n",
    "reactions = nombre_reactions()\n",
    "time.sleep(10)\n",
    "\n",
    "extract_publications_links()\n",
    "\n",
    "for lien in liens_publications:\n",
    "    desc=extract_description(lien)\n",
    "    descriptions.append(desc)\n",
    "\n",
    "for d in descriptions:\n",
    "    produit =  produit_par_publication(d)\n",
    "    produits.append(produit)\n",
    "\n",
    "\n",
    "    \n",
    "for lien in liens_publications:\n",
    "    driver.get(lien)\n",
    "    react = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[3]/a').get_attribute('href')\n",
    "    time.sleep(10)\n",
    "    driver.get(react)\n",
    "    like = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/table/tbody/tr/td/div/div/a[2]/span').text\n",
    "    love = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/table/tbody/tr/td/div/div/a[3]/span').text\n",
    "    try:\n",
    "        angry = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/table/tbody/tr/td/div/div/a[4]/img').get_attribute('alt')\n",
    "        if (angry=='Angry'):\n",
    "            angry = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/table/tbody/tr/td/div/div/a[4]/span').text\n",
    "        else:\n",
    "            angry='0'\n",
    "    except:\n",
    "        angry='0'\n",
    "    likes.append(like)\n",
    "    loves.append(love)\n",
    "    angryy.append(angry)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3b9bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a Pandas dataframe from the data.\n",
    "df = pd.DataFrame({'links': liens_publications,'description':descriptions, 'produit': produits ,'reactions': reactions ,'Like' : likes , 'love' : loves ,'Angry':angryy})\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('pandas_simple4.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89e2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "def extract_commentaires():\n",
    "    err=''\n",
    "    i=1\n",
    "    comments=[]\n",
    "    done=False\n",
    "    try:\n",
    "        while(True):\n",
    "                try:\n",
    "                    commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/div[1]')\n",
    "                    i=i+1\n",
    "                    #print(commentaire.text)\n",
    "                    comments.append(commentaire.text)\n",
    "                except:\n",
    "                    while(True):\n",
    "                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                        page.click()\n",
    "                        #print('ok')\n",
    "                        j=10\n",
    "                        try:\n",
    "                            i=2\n",
    "                            while(True):\n",
    "                                commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/div[1]')\n",
    "                                i=i+1\n",
    "                                #print(commentaire.text)\n",
    "                                comments.append(commentaire.text)\n",
    "                                j=j+10\n",
    "\n",
    "                        except:\n",
    "                            while(True):\n",
    "                                try:\n",
    "                                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                                        page.click()\n",
    "                                        #print('ok')\n",
    "                                        i=2\n",
    "                                        while(True):\n",
    "                                            commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/div[1]')\n",
    "                                            i=i+1\n",
    "                                            #print(commentaire.text)    \n",
    "                                            comments.append(commentaire.text)\n",
    "                                        j=j+10\n",
    "                                except NoSuchElementException:\n",
    "                                    done=True\n",
    "                                    break\n",
    "\n",
    "    except:\n",
    "                    err='erreur'\n",
    "    return(comments)\n",
    "\n",
    "\n",
    "users=[]\n",
    "def extract_user_names():\n",
    "    err=''\n",
    "    i=1\n",
    "    comments=[]\n",
    "    done=False\n",
    "    try:\n",
    "        while(True):\n",
    "                try:\n",
    "                    commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/h3/a')\n",
    "                    i=i+1\n",
    "                    #print(commentaire.text)\n",
    "                    users.append(commentaire.text)\n",
    "                except:\n",
    "                    while(True):\n",
    "                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                        page.click()\n",
    "                        #print('ok')\n",
    "                        j=10\n",
    "                        try:\n",
    "                            i=2\n",
    "                            while(True):\n",
    "                                commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/h3/a')\n",
    "                                i=i+1\n",
    "                                #print(commentaire.text)\n",
    "                                users.append(commentaire.text)\n",
    "                                j=j+10\n",
    "\n",
    "                        except:\n",
    "                            while(True):\n",
    "                                try:\n",
    "                                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                                        page.click()\n",
    "                                        #print('ok')\n",
    "                                        i=2\n",
    "                                        while(True):\n",
    "                                            commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/h3/a')\n",
    "                                            i=i+1\n",
    "                                            #print(commentaire.text)\n",
    "                                            users.append(commentaire.text)\n",
    "                                            j=j+10\n",
    "                                except NoSuchElementException:\n",
    "                                    done=True\n",
    "                                    break\n",
    "\n",
    "    except:\n",
    "                    err='erreur'\n",
    "    return(users)\n",
    "\n",
    "\n",
    "import time \n",
    "import pandas as pd\n",
    "\n",
    "commentaires=[]\n",
    "cl =[]\n",
    "links=[]\n",
    "writer = pd.ExcelWriter('publications2.xlsx', engine='xlsxwriter')\n",
    "i=1\n",
    "\n",
    "for lien in liens_publications:\n",
    "    comments=[]\n",
    "    users=[]\n",
    "    link=[]\n",
    "    driver.get(lien)\n",
    "    time.sleep(10)\n",
    "    comments=extract_commentaires()\n",
    "    time.sleep(10)\n",
    "    driver.get(lien)\n",
    "    users = extract_user_names()\n",
    "    df = pd.DataFrame({'user': users,'commentaire':comments})\n",
    "    df.to_excel(writer, sheet_name='Pub Num'+str(i))\n",
    "    i=i+1\n",
    "    for j in range(len(users)):\n",
    "        link.append(lien)\n",
    "    #print(comments)\n",
    "    #print(users)\n",
    "    cl = cl + users\n",
    "    commentaires = commentaires + comments\n",
    "    links=links+link\n",
    "\n",
    "    \n",
    "df1 = pd.DataFrame({'lien publication':links,'user': cl,'commentaire':commentaires})\n",
    "df1.to_excel(writer, sheet_name='All')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79db0a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dream\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:336: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e36f9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur\n",
      "50\n",
      "erreur\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#Corrections\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "def extract_commentaires():\n",
    "    i=1\n",
    "    comments=[]\n",
    "    done=False\n",
    "    try:\n",
    "        while(True):\n",
    "                try:\n",
    "                    commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/div[1]')\n",
    "                    i=i+1\n",
    "                    #print(commentaire.text)\n",
    "                    comments.append(commentaire.text)\n",
    "                except:\n",
    "                    while(True):\n",
    "                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                        page.click()\n",
    "                        #print('ok')\n",
    "                        j=10\n",
    "                        try:\n",
    "                            i=2\n",
    "                            while(True):\n",
    "                                commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/div[1]')\n",
    "                                i=i+1\n",
    "                                #print(commentaire.text)\n",
    "                                comments.append(commentaire.text)\n",
    "                                j=j+10\n",
    "\n",
    "                        except:\n",
    "                            while(True):\n",
    "                                try:\n",
    "                                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                                        page.click()\n",
    "                                        #print('ok')\n",
    "                                        i=2\n",
    "                                        while(True):\n",
    "                                            commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/div[1]')\n",
    "                                            i=i+1\n",
    "                                            #print(commentaire.text)    \n",
    "                                            comments.append(commentaire.text)\n",
    "                                        j=j+10\n",
    "                                except NoSuchElementException:\n",
    "                                    done=True\n",
    "                                    break\n",
    "\n",
    "    except:\n",
    "                    print('erreur')\n",
    "    return(comments)\n",
    "driver.get('https://mbasic.facebook.com/story.php?story_fbid=1750414488477444&id=421001574752082&refid=17&_ft_=mf_story_key.1750414488477444%3Atop_level_post_id.1750414488477444%3Atl_objid.1750414488477444%3Acontent_owner_id_new.421001574752082%3Athrowback_story_fbid.1750414488477444%3Apage_id.421001574752082%3Astory_location.4%3Astory_attachment_style.photo%3Aott.AX_5EAqMM6g3uW0v%3Atds_flgs.3%3Athid.421001574752082%3A306061129499414%3A2%3A0%3A1633071599%3A4631501828048357028%3A%3A&__tn__=%2AW-R')\n",
    "res=extract_commentaires()\n",
    "print(len(res))\n",
    "\n",
    "users=[]\n",
    "def extract_user_names():\n",
    "    i=1\n",
    "    comments=[]\n",
    "    done=False\n",
    "    try:\n",
    "        while(True):\n",
    "                try:\n",
    "                    commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/h3/a')\n",
    "                    i=i+1\n",
    "                    #print(commentaire.text)\n",
    "                    users.append(commentaire.text)\n",
    "                except:\n",
    "                    while(True):\n",
    "                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                        page.click()\n",
    "                        #print('ok')\n",
    "                        j=10\n",
    "                        try:\n",
    "                            i=2\n",
    "                            while(True):\n",
    "                                commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/h3/a')\n",
    "                                i=i+1\n",
    "                                #print(commentaire.text)\n",
    "                                users.append(commentaire.text)\n",
    "                                j=j+10\n",
    "\n",
    "                        except:\n",
    "                            while(True):\n",
    "                                try:\n",
    "                                        page = driver.find_element_by_link_text('View more comments…')\n",
    "                                        page.click()\n",
    "                                        #print('ok')\n",
    "                                        i=2\n",
    "                                        while(True):\n",
    "                                            commentaire = driver.find_element_by_xpath('/html/body/div/div/div[2]/div/div[1]/div[2]/div/div[5]/div['+str(i)+']/div/h3/a')\n",
    "                                            i=i+1\n",
    "                                            #print(commentaire.text)\n",
    "                                            users.append(commentaire.text)\n",
    "                                            j=j+10\n",
    "                                except NoSuchElementException:\n",
    "                                    done=True\n",
    "                                    break\n",
    "\n",
    "    except:\n",
    "                    print('erreur')\n",
    "    return(users)\n",
    "\n",
    "driver.get('https://mbasic.facebook.com/story.php?story_fbid=1750414488477444&id=421001574752082&refid=17&_ft_=mf_story_key.1750414488477444%3Atop_level_post_id.1750414488477444%3Atl_objid.1750414488477444%3Acontent_owner_id_new.421001574752082%3Athrowback_story_fbid.1750414488477444%3Apage_id.421001574752082%3Astory_location.4%3Astory_attachment_style.photo%3Aott.AX_5EAqMM6g3uW0v%3Atds_flgs.3%3Athid.421001574752082%3A306061129499414%3A2%3A0%3A1633071599%3A4631501828048357028%3A%3A&__tn__=%2AW-R')\n",
    "res=extract_user_names()\n",
    "print(len(res))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2797e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaire = [\"chahriya\",\"double salaire\",\"chahriya\",\"chahreya\",\"chheri\",\"chahryet\",\"شهريتي\",\"شهرية\",\"شهري\"]\n",
    "credit = [\"9ardh\",\"9arth\",\"9ardhi\",\"Crédit\",\"credit\",\"كريدي\",\"القرض\",\"قرض\",\"قرضي\",\"الشيكات\"]\n",
    "carte = [\"البطاقة البنكية\",\"البطاقة\",\"Carte Banquaire\",\"carte\",\"الكارطة\",\"STBNet\"]\n",
    "service = [\"الموزع الآلي\",\"les queues\",\"التليفون\",\"téléphone\",\"service\",\"saff\",\" queues \",\"الصف\",\" استفسار\",\"distributeur \",\"تحويل الأموال\",\"transfert de compte\"]\n",
    "\n",
    "def est_credit(c):\n",
    "    credit = [\"9ardh\",\"9arth\",\"9ardhi\",\"Crédit\",\"credit\",\"كريدي\",\"القرض\",\"قرض\",\"قرضي\",\"الشيكات\"]\n",
    "    res=False\n",
    "    for p in credit:\n",
    "        if(type(c)==list):\n",
    "            break\n",
    "        if(c.find(p)!=-1):\n",
    "            res=True\n",
    "            break\n",
    "    return(res)\n",
    "    \n",
    "def est_salaire(c):\n",
    "    salaire = [\"فلوسنا\",\"chahriya\",\"double salaire\",\"chahriya\",\"chahreya\",\"chheri\",\"chahryet\",\"شهريتي\",\"شهرية\",\"شهري\"]\n",
    "    res=False\n",
    "    for p in salaire:\n",
    "        if(type(c)==list):\n",
    "            break\n",
    "        if(c.find(p)!=-1):\n",
    "            res=True\n",
    "            break\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def est_carte(c):\n",
    "    carte = [\"البطاقة البنكية\",\"البطاقة\",\"Carte Banquaire\",\"carte\",\"الكارطة\",\"STBNet\"]\n",
    "    res=False\n",
    "    for p in carte:\n",
    "        if(type(c)==list):\n",
    "            break\n",
    "        if(c.find(p)!=-1):\n",
    "            res=True\n",
    "            break\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def est_service(c):\n",
    "    service = [\"الموزع الآلي\",\"les queues\",\"التليفون\",\"téléphone\",\"service\",\"saff\",\" queues \",\"الصف\",\" استفسار\",\"distributeur \",\"تحويل الأموال\",\"transfert de compte\"]\n",
    "    res=False\n",
    "    for p in service:\n",
    "        if(type(c)==list):\n",
    "            break\n",
    "        if(c.find(p)!=-1):\n",
    "            res=True\n",
    "            break\n",
    "    return(res)\n",
    "#EXCEL N2 \n",
    "produit=[]\n",
    "publication=[]\n",
    "comments=[]\n",
    "\n",
    "Crédit=[]\n",
    "Salaire=[]\n",
    "Carte=[]\n",
    "Service =[]\n",
    "\n",
    "for c in commentaires:\n",
    "    if(est_credit(c)):\n",
    "        Crédit.append(\"V\")\n",
    "        produit.append(\"Crédit\")\n",
    "        publication.append(links[commentaires.index(c)])\n",
    "        comments.append(c)\n",
    "    else:\n",
    "        Crédit.append(\"F\")\n",
    "    if(est_salaire(c)==True):\n",
    "        Salaire.append(\"V\")\n",
    "        produit.append(\"Salaire\")\n",
    "        publication.append(links[commentaires.index(c)])\n",
    "        comments.append(c)\n",
    "    else:\n",
    "        Salaire.append(\"F\")\n",
    "    if(est_carte(c)==True):\n",
    "        Carte.append(\"V\")\n",
    "        produit.append(\"Carte\")\n",
    "        publication.append(links[commentaires.index(c)])\n",
    "        comments.append(c)\n",
    "    else:\n",
    "        Carte.append(\"F\")\n",
    "    if(est_service(c)==True):\n",
    "        Service.append(\"V\")\n",
    "        produit.append(\"Autre\")\n",
    "        publication.append(links[commentaires.index(c)])\n",
    "        comments.append(c)\n",
    "    else:\n",
    "        Service.append(\"F\")\n",
    "    \n",
    "\n",
    "    \n",
    "import pandas as pd\n",
    "# Create a Pandas dataframe from the data.\n",
    "df = pd.DataFrame({'user': cl,'lien publication':links,'commentaire':commentaires, 'Crédit': Crédit , 'Salaire': Salaire ,'Carte': Carte , 'Autres Services': Service})\n",
    "df1= pd.DataFrame({'lien publication':publication,'commentaire':comments,'Type de Produit':produit})\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('All3.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "df1.to_excel(writer, sheet_name='Sheet2')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc97ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
